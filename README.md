#  طبقه‌بند احساسات با Bag-of-Words و Naive Bayes

این یک پروژه‌ی کلاسیک در پردازش زبان طبیعی (NLP) است که یک مدل یادگیری ماشین را برای طبقه‌بندی نظرات رستوران‌ها به عنوان **«مثبت» (Positive)** یا **«منفی» (Negative)** آموزش می‌دهد.

این پروژه از الگوریتم **Bag-of-Words (BoW)** برای تبدیل متن به داده‌های عددی و از طبقه‌بند **Gaussian Naive Bayes** برای انجام پیش‌بینی استفاده می‌کند.

---

## 📊 دیتاست (Dataset)

دیتاست استفاده‌شده، فایل `Restaurant_Reviews.tsv` است که شامل ۱۰۰۰ نظر در مورد رستوران‌ها می‌باشد. این دیتاست دارای دو ستون اصلی است:
* **`Review`**: متن نظر مشتری.
* **`Liked`**: برچسب احساسات ( `1` برای مثبت، `0` برای منفی).

---

## ⚙️ فرآیند و متدولوژی (Workflow)

این پروژه دقیقاً از مراحل زیر پیروی می‌کند:

### ۱. پاک‌سازی متن (Text Preprocessing)
برای آماده‌سازی متن برای مدل، یک «مجموعه» (Corpus) از نظرات پاک‌سازی‌شده ساخته می‌شود. برای هر نظر:
1.  **حذف علائم و اعداد**: تمام کاراکترهای غیرانگلیسی (مانند `.`، `!`، و اعداد) با استفاده از Regex (`[^a-zA-Z]`) حذف می‌شوند.
2.  **کوچک‌سازی حروف**: تمام متن به حروف کوچک تبدیل می‌شود.
3.  **حذف کلمات توقف (Stopwords)**: کلمات رایج انگلیسی (مانند `the`, `is`, `a`) با استفاده از `NLTK` حذف می‌شوند.
4.  **یک استثنای هوشمندانه**: کلمه‌ی **`not`** از لیست کلمات توقف حذف می‌شود، زیرا این کلمه برای درک احساسات (مثلاً "not good") حیاتی است.
5.  **ریشه‌یابی (Stemming)**: کلمات به ریشه‌ی خود بازگردانده می‌شوند (مثلاً `loving` به `love` تبدیل می‌شود) تا تعداد کلمات منحصر به فرد کاهش یابد.

### ۲. ساخت مدل Bag-of-Words (BoW)
1.  از `CountVectorizer` کتابخانه‌ی `Scikit-learn` برای شمارش فراوانی کلمات در کل مجموعه (Corpus) استفاده می‌شود.
2.  برای جلوگیری از پیچیدگی بیش از حد، مدل به **۱۵۰۰ کلمه‌ی پرتکرار** (`max_features = 1500`) محدود شده است.
3.  خروجی یک ماتریس اسپارس (`X`) است که در آن هر سطر یک نظر و هر ستون یک کلمه‌ی منحصر به فرد است.

### ۳. آموزش و ارزیابی مدل
1.  دیتاست به دو بخش **۸۰٪ آموزشی (Train)** و **۲۰٪ آزمایشی (Test)** تقسیم می‌شود (`test_size = 0.20`).
2.  یک مدل **Gaussian Naive Bayes** (`GaussianNB`) بر روی داده‌های آموزشی، آموزش داده می‌شود.
3.  عملکرد مدل با پیش‌بینی روی داده‌های آزمایشی و محاسبه‌ی **Confusion Matrix** (ماتریس درهم‌ریختگی) و **Accuracy Score** (امتیاز دقت) ارزیابی می‌شود.

---

## 🛠️ کتابخانه‌های استفاده‌شده (Technologies Used)

* **Python 3.x**
* **Pandas**: برای بارگذاری و مدیریت دیتاست (`.tsv`).
* **NLTK**: برای پاک‌سازی متن، مدیریت `stopwords` و `PorterStemmer`.
* **Scikit-learn (`sklearn`)**: برای `CountVectorizer`، `train_test_split`، مدل `GaussianNB` و معیارهای ارزیابی (`confusion_matrix`, `accuracy_score`).
* **Numpy**: برای عملیات‌های عددی.

---

##  نحوه اجرا (How to Run)

1.  این ریپازیتوری را `clone` کنید:
    ```bash
    git clone [https://github.com/erfan-8/BoW-Sentiment-Classifier.git](https://github.com/erfan-8/BoW-Sentiment-Classifier.git)
    ```
2.  وارد پوشه‌ی پروژه شوید:
    ```bash
    cd BoW-Sentiment-Classifier
    ```
3.  کتابخانه‌های مورد نیاز را نصب کنید:
    ```bash
    pip install numpy pandas matplotlib nltk scikit-learn
    ```
4.  (فقط برای بار اول) بسته‌ی `stopwords` کتابخانه‌ی NLTK را دانلود کنید. یک اسکریپت پایتون باز کنید و اجرا کنید:
    ```python
    import nltk
    nltk.download('stopwords')
    ```
5.  اسکریپت اصلی (`natural_language_processing.py`) را اجرا کنید تا مدل آموزش ببیند و نتایج (Confusion Matrix و Accuracy) در ترمینال چاپ شوند.
